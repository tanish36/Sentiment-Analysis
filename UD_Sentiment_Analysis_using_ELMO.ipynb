{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UD Sentiment Analysis using ELMO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanish36/Tensorflow-Projects/blob/master/UD_Sentiment_Analysis_using_ELMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdYt8oDcp9Lg",
        "colab_type": "text"
      },
      "source": [
        "<h1>Making a Twitter Sentiment Analysis using The Elmo text Embemding from tfhub\n",
        "\n",
        "IMPORTING THE REQUIRED LIBRARIES <br>\n",
        "\n",
        "Using Tensorflow 1.15 as the Elmo Model used here is not supported in the Tensorflow 2.x but will be in the the future"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INgDsvk59dkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhFGL97ZtKAK",
        "colab_type": "text"
      },
      "source": [
        "<h2>Importing the required file\n",
        "\n",
        "Importing the file of the twitter tweets from 2016 Presidential debate using the Pandas Library for it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsgOWGBK6OjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df =  pd.read_csv(\"https://raw.githubusercontent.com/tanish36/Tensorflow-Projects/master/Sentiment.csv\",encoding=\"latin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJyY2_KTfKcN",
        "colab_type": "text"
      },
      "source": [
        "Using the df.info() to check the info of the iported file that we are going to use <br>we can see that their are 13871 total entries in the id block and the different data type of the of the each column "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6jXsgn7nQ_",
        "colab_type": "code",
        "outputId": "326e9e84-b7a4-4c1f-cfce-6bd5dbd66e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13871 entries, 0 to 13870\n",
            "Data columns (total 21 columns):\n",
            "id                           13871 non-null int64\n",
            "candidate                    13775 non-null object\n",
            "candidate_confidence         13871 non-null float64\n",
            "relevant_yn                  13871 non-null object\n",
            "relevant_yn_confidence       13871 non-null float64\n",
            "sentiment                    13871 non-null object\n",
            "sentiment_confidence         13871 non-null float64\n",
            "subject_matter               13545 non-null object\n",
            "subject_matter_confidence    13871 non-null float64\n",
            "candidate_gold               28 non-null object\n",
            "name                         13871 non-null object\n",
            "relevant_yn_gold             32 non-null object\n",
            "retweet_count                13871 non-null int64\n",
            "sentiment_gold               15 non-null object\n",
            "subject_matter_gold          18 non-null object\n",
            "text                         13871 non-null object\n",
            "tweet_coord                  21 non-null object\n",
            "tweet_created                13871 non-null object\n",
            "tweet_id                     13871 non-null int64\n",
            "tweet_location               9959 non-null object\n",
            "user_timezone                9468 non-null object\n",
            "dtypes: float64(4), int64(3), object(14)\n",
            "memory usage: 2.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Y5PQ1Hqnqp",
        "colab_type": "text"
      },
      "source": [
        "Getting the info on our dataset and labelling the sentiments as <br>\n",
        "1. Neutral as 0<br>\n",
        "2. Positive as 1<br>\n",
        "3. Negative as 2 <br>\n",
        "\n",
        "we are doing the encoding as we are using the logistic Regression model for the implementation which predicts value on the basis of the numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "youUT6eddYGf",
        "colab_type": "code",
        "outputId": "25b2ceb6-9084-44a4-818d-3de6609b0f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "df.loc[df[\"sentiment\"]=='Neutral',\"sentiment\"]=0\n",
        "df.loc[df[\"sentiment\"]=='Negative',\"sentiment\"]=1\n",
        "df.loc[df[\"sentiment\"]=='Positive',\"sentiment\"]=2\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>candidate</th>\n",
              "      <th>candidate_confidence</th>\n",
              "      <th>relevant_yn</th>\n",
              "      <th>relevant_yn_confidence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_confidence</th>\n",
              "      <th>subject_matter</th>\n",
              "      <th>subject_matter_confidence</th>\n",
              "      <th>candidate_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>relevant_yn_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>sentiment_gold</th>\n",
              "      <th>subject_matter_gold</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>No candidate mentioned</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6578</td>\n",
              "      <td>None of the above</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I_Am_Kenzi</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-08-07 09:54:46 -0700</td>\n",
              "      <td>629697200650592256</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Quito</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Scott Walker</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>None of the above</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PeacefulQuest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-08-07 09:54:46 -0700</td>\n",
              "      <td>629697199560069120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>No candidate mentioned</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>None of the above</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PussssyCroook</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-08-07 09:54:46 -0700</td>\n",
              "      <td>629697199312482304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>No candidate mentioned</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>None of the above</td>\n",
              "      <td>0.7039</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MattFromTexas31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-08-07 09:54:45 -0700</td>\n",
              "      <td>629697197118861312</td>\n",
              "      <td>Texas</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Donald Trump</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.7045</td>\n",
              "      <td>None of the above</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sharonDay5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>156</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-08-07 09:54:45 -0700</td>\n",
              "      <td>629697196967903232</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Arizona</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id               candidate  ...  tweet_location               user_timezone\n",
              "0   1  No candidate mentioned  ...             NaN                       Quito\n",
              "1   2            Scott Walker  ...             NaN                         NaN\n",
              "2   3  No candidate mentioned  ...             NaN                         NaN\n",
              "3   4  No candidate mentioned  ...           Texas  Central Time (US & Canada)\n",
              "4   5            Donald Trump  ...             NaN                     Arizona\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_Ul-PDorRcV",
        "colab_type": "text"
      },
      "source": [
        "<h2>Making a list of data for training\n",
        "\n",
        "making a training dat which we will feed into the tf hub ELMO model for generating the feature vectors we are usinf only 131 tweet fromt the datset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIoiKrPrBBKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df[\"text\"])\n",
        "y = np.array(df[\"sentiment\"])\n",
        "l=[]\n",
        "for i in range (131):\n",
        "  l.append(df['text'][i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCwZdt56rac2",
        "colab_type": "text"
      },
      "source": [
        "<h2>Test Dataset\n",
        "\n",
        "Using the two set of tweet for testing the data after making the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0XIbYgxCND0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_text =  ['RT @FrankLuntz: Before the #GOPDebate, 14 focus groupers said they did not have favorable view of Trump.',\n",
        "             'Chris Wallace(D) to be the 2nd worst partisan pontificating asshole \"moderating\" #GOPDebate @megynkelly'\n",
        "            ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFY2fA4Nrehf",
        "colab_type": "text"
      },
      "source": [
        "<h2>Spliting the data into the training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsC6CFZ2GD36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7lhM5l2rk5a",
        "colab_type": "text"
      },
      "source": [
        "Using the Tensorflow hub library for elmo\n",
        "\n",
        "importing the Elmo Model from TF HUB "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4ouHhr1O61u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJKFOvUgmT_G",
        "colab_type": "text"
      },
      "source": [
        "using the Elmo Model for Generarting the feature set for the taken dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n0DedjpdJcL",
        "colab_type": "text"
      },
      "source": [
        "The output is a 3 dimensional tensor of shape (131, 28, 1024):\n",
        "\n",
        "The first dimension of this tensor represents the number of training samples. This is 131 in our case<br>\n",
        "The second dimension represents the maximum length of the longest string in the input list of strings.<br>\n",
        "The third dimension is equal to the length of the ELMo vector which is 1024"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyonQiMjPmZ0",
        "colab_type": "code",
        "outputId": "a4a7d5ea-7c32-45f5-d379-9be32f167d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings = elmo(l, signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "\n",
        "embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(131), Dimension(28), Dimension(1024)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4naUAQoChU",
        "colab_type": "text"
      },
      "source": [
        "Making the elmo_vector function which will process the data to generate the elmo model feature set\n",
        "and return the mean of the feature set result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqhYQRmcP439",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def elmo_vectors(x):\n",
        "  embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    # return average of ELMo features\n",
        "    return sess.run(tf.reduce_mean(embeddings,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2tNuETpr5dZ",
        "colab_type": "text"
      },
      "source": [
        "Doing the preprocessing on the data for Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0X10xB9eiKB",
        "colab_type": "code",
        "outputId": "8faee797-8ab5-4573-d5e1-f562791dbf56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "elmo_train = [elmo_vectors(l) ]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzrKHv2vpHRu",
        "colab_type": "text"
      },
      "source": [
        "Concatenate the result of the elmo train in the single array int he next step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28RbRZUDl1vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo_train_new = np.concatenate(elmo_train, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrI-D8S_p8tE",
        "colab_type": "text"
      },
      "source": [
        "defing the next variable for the logistic regression as yy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_qkm-IblCCT",
        "colab_type": "code",
        "outputId": "88fa502f-e4af-4972-9d36-6fd385eba43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "yy=df['sentiment'].iloc[:131]\n",
        "yy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      2\n",
              "2      0\n",
              "3      2\n",
              "4      2\n",
              "      ..\n",
              "126    1\n",
              "127    2\n",
              "128    0\n",
              "129    1\n",
              "130    1\n",
              "Name: sentiment, Length: 131, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfCnhdbcsGQ0",
        "colab_type": "text"
      },
      "source": [
        "<h2>Using the Logistic Regression for Analysis and training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ccZBZdUqP0A",
        "colab_type": "code",
        "outputId": "90d51543-bfb3-4c1e-b502-cb462ce5ba55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(yy.shape,elmo_train_new.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(131,) (131, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq8JSrw7tDF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regressor = tf.estimator.LogisticRegressionHead()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Vm6aSstCiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTi4Lhz2tCOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNW1EHNCd4Sz",
        "colab_type": "code",
        "outputId": "287ae25c-f816-4a38-e769-c1927e26b5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "lreg = LogisticRegression()\n",
        "lreg.fit(elmo_train_new, yy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3osCOVxeCtQ",
        "colab_type": "code",
        "outputId": "98ab92fb-2dc5-43cd-eb98-64f95582c110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "j=[df['text'][i] for i in range(132,184)]\n",
        "el = [elmo_vectors(j)]\n",
        "elmotestnew = np.concatenate(el, axis = 0)\n",
        "#preds_valid = lreg.predict(xtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONGTmY51sQ_m",
        "colab_type": "text"
      },
      "source": [
        "<h1>Predicting the value\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5trfRm5PmZZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_valid = lreg.predict(elmotestnew)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "925U8aQrnSlT",
        "colab_type": "code",
        "outputId": "e2a005c1-df55-4a7a-d880-dde7bf02f60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "lab=[df['sentiment'][i] for i in range(132,184)]\n",
        "lab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRIrTh-Psb6y",
        "colab_type": "text"
      },
      "source": [
        "Compairing the predicted value and real value using f1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4QW47hCnxGw",
        "colab_type": "code",
        "outputId": "b5d586fe-e094-4fa8-c4ac-4f52d7f6686a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "#preds_valid\n",
        "f1_score(lab, preds_valid,average='micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6538461538461539"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XEN-qaVsqKn",
        "colab_type": "text"
      },
      "source": [
        "Predicting the value for a small dataset of two length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgSYgb-3n7N2",
        "colab_type": "code",
        "outputId": "7c14e15b-d950-4097-9fd6-6025f6d517e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "el1 = [elmo_vectors(new_text)]\n",
        "elmotestnew1 = np.concatenate(el1, axis = 0)\n",
        "jj=lreg.predict(elmotestnew1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjJz9geKs0Zm",
        "colab_type": "text"
      },
      "source": [
        "<h2>Predicted Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiYy95lJoqY5",
        "colab_type": "code",
        "outputId": "3f442723-bc5b-46de-83f2-fd81bfc9ec04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for i in jj:\n",
        "  if i==0:\n",
        "    print(\"NEUTRAL\")\n",
        "  elif i==1:\n",
        "    print(\"Positive\")\n",
        "  elif i==2:\n",
        "    print(\"Negative\")    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative\n",
            "Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXEAwPBtpAQU",
        "colab_type": "code",
        "outputId": "5923e928-64d6-4e09-ab2a-6b1ef69163a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for i in jj:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AzYU23HdjQF",
        "colab_type": "text"
      },
      "source": [
        "REFERENCES<BR>\n",
        "1.https://towardsdatascience.com/transfer-learning-using-elmo-embedding-c4a7e415103c <br>\n",
        "2.https://tfhub.dev/google/elmo/3 <br>\n",
        "3.https://medium.com/learning-machine-learning/introduction-to-tensorflow-estimators-part-1-39f9eb666bc7"
      ]
    }
  ]
}